{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyasbkgit/dllab/blob/main/Week3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Week-3:** Design Deep forward Neural Network for image classification\n",
        "- Design and implement an Image classification model to classify a dataset of images using Deep\n",
        "   Feed Forward NN.\n",
        "- Use the MNIST datasets.\n",
        "- Record the accuracy corresponding to the number of epochs 5, 50, 100.\n",
        "- Repeat for CIFAR10 datasets. Note down the changes made and the accuracies obtained.\n"
      ],
      "metadata": {
        "id": "BdUIzGg4p7N5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST Dataset: https://www.kaggle.com/datasets/hojjatk/mnist-dataset"
      ],
      "metadata": {
        "id": "nYPA2tbqqdB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR10 and CIFAR100 Datasets(University of Toronto): https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "metadata": {
        "id": "GQV-U7l8qmfB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR10 Dataset (Kaggle): https://www.kaggle.com/c/cifar-10/"
      ],
      "metadata": {
        "id": "3W-4d5S2qqoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fashion MNIST Dataset(Kaggle): https://www.kaggle.com/datasets/zalando-research/fashionmnist"
      ],
      "metadata": {
        "id": "2-Ftlv3dsnD5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gatCpdstp20t"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras import Input\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load digits data\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Print shapes\n",
        "print(\"Shape of X_train: \", X_train.shape)\n",
        "print(\"Shape of y_train: \", y_train.shape)\n",
        "print(\"Shape of X_test: \", X_test.shape)\n",
        "print(\"Shape of y_test: \", y_test.shape)\n",
        "\n",
        "# Display images of the first 10 digits in the training set and their true labels\n",
        "fig, axs = plt.subplots(2, 5, figsize=(12, 6), facecolor='white')\n",
        "n = 0\n",
        "for i in range(2):\n",
        "    for j in range(5):\n",
        "        axs[i, j].imshow(X_train[n], cmap='gray')\n",
        "        axs[i, j].set_title(f\"Label: {y_train[n]}\")\n",
        "        axs[i, j].axis('off')\n",
        "        n += 1\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Reshape and normalize input data\n",
        "X_train = X_train.reshape(60000, 784).astype(\"float32\") / 255\n",
        "X_test = X_test.reshape(10000, 784).astype(\"float32\") / 255\n",
        "\n",
        "# Print new shapes\n",
        "print(\"New shape of X_train: \", X_train.shape)\n",
        "print(\"New shape of X_test: \", X_test.shape)\n",
        "\n",
        "# Design the Deep Feedforward Neural Network architecture\n",
        "model = Sequential(name=\"DFF-Model\")\n",
        "model.add(Input(shape=(784,), name='Input-Layer'))\n",
        "model.add(Dense(128, activation='relu', name='Hidden-Layer-1', kernel_initializer='he_normal'))\n",
        "model.add(Dense(64, activation='relu', name='Hidden-Layer-2', kernel_initializer='he_normal'))\n",
        "model.add(Dense(32, activation='relu', name='Hidden-Layer-3', kernel_initializer='he_normal'))\n",
        "model.add(Dense(10, activation='softmax', name='Output-Layer'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=10,\n",
        "                    epochs=50,\n",
        "                    verbose='auto',\n",
        "                    validation_split=0.2,\n",
        "                    shuffle=True)\n",
        "\n",
        "# Predict class labels\n",
        "pred_labels_tr = np.array(tf.math.argmax(model.predict(X_train), axis=1))\n",
        "pred_labels_te = np.array(tf.math.argmax(model.predict(X_test), axis=1))\n",
        "\n",
        "# Model Summary\n",
        "print(\"\\nModel Summary:\")\n",
        "model.summary()\n",
        "\n",
        "# Optionally: print shapes of weights and biases for each layer\n",
        "# for layer in model.layers:\n",
        "#     weights = layer.get_weights()\n",
        "#     if weights:\n",
        "#         print(f\"Layer: {layer.name}\")\n",
        "#         print(f\" -- Weights shape: {weights[0].shape}\")\n",
        "#         print(f\" -- Biases shape: {weights[1].shape}\")\n",
        "\n",
        "# Evaluation on training data\n",
        "print(\"\\n---------- Evaluation on Training Data -----------\")\n",
        "print(classification_report(y_train, pred_labels_tr))\n",
        "\n",
        "# Evaluation on test data\n",
        "print(\"\\n---------- Evaluation on Test Data -----------\")\n",
        "print(classification_report(y_test, pred_labels_te))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To-Do:\n",
        "Use the MNIST datasets.\n",
        "\n",
        "Use the CIFAR10 datasets.\n",
        "\n",
        "*Record the accuracy corresponding to the number of epochs 5, 50, 100.\n",
        "\n",
        "*Repeat for CIFAR10 datasets. Note down the changes made and the accuracies obtained.\n",
        "\n",
        "*Use the Fashion MNIST Dataset\n",
        "\n",
        "*Perform and Plot the Comparative Analysis.\n"
      ],
      "metadata": {
        "id": "N-Vs541Lq-Gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras import Input\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# ==== GPU CHECK FOR COLAB ====\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Enable memory growth for GPU\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"✅ GPU is available and memory growth is set.\")\n",
        "    except RuntimeError as e:\n",
        "        print(\"Error setting up GPU:\", e)\n",
        "else:\n",
        "    print(\"❌ No GPU found. Using CPU.\")\n",
        "\n",
        "# ==== Load digits data ====\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Print shapes\n",
        "print(\"Shape of X_train: \", X_train.shape)\n",
        "print(\"Shape of y_train: \", y_train.shape)\n",
        "print(\"Shape of X_test: \", X_test.shape)\n",
        "print(\"Shape of y_test: \", y_test.shape)\n",
        "\n",
        "# Display images of the first 10 digits in the training set and their true labels\n",
        "fig, axs = plt.subplots(2, 5, figsize=(12, 6), facecolor='white')\n",
        "n = 0\n",
        "for i in range(2):\n",
        "    for j in range(5):\n",
        "        axs[i, j].imshow(X_train[n], cmap='gray')\n",
        "        axs[i, j].set_title(f\"Label: {y_train[n]}\")\n",
        "        axs[i, j].axis('off')\n",
        "        n += 1\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Reshape and normalize input data\n",
        "X_train = X_train.reshape(60000, 784).astype(\"float32\") / 255\n",
        "X_test = X_test.reshape(10000, 784).astype(\"float32\") / 255\n",
        "\n",
        "# Print new shapes\n",
        "print(\"New shape of X_train: \", X_train.shape)\n",
        "print(\"New shape of X_test: \", X_test.shape)\n",
        "\n",
        "# ==== Design the Deep Feedforward Neural Network architecture ====\n",
        "model = Sequential(name=\"DFF-Model\")\n",
        "model.add(Input(shape=(784,), name='Input-Layer'))\n",
        "model.add(Dense(128, activation='relu', name='Hidden-Layer-1', kernel_initializer='he_normal'))\n",
        "model.add(Dense(64, activation='relu', name='Hidden-Layer-2', kernel_initializer='he_normal'))\n",
        "model.add(Dense(32, activation='relu', name='Hidden-Layer-3', kernel_initializer='he_normal'))\n",
        "model.add(Dense(10, activation='softmax', name='Output-Layer'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# ==== Train the model ====\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=10,\n",
        "                    epochs=50,\n",
        "                    verbose='auto',\n",
        "                    validation_split=0.2,\n",
        "                    shuffle=True)\n",
        "\n",
        "# ==== Predictions ====\n",
        "pred_labels_tr = np.array(tf.math.argmax(model.predict(X_train), axis=1))\n",
        "pred_labels_te = np.array(tf.math.argmax(model.predict(X_test), axis=1))\n",
        "\n",
        "# ==== Model Summary ====\n",
        "print(\"\\nModel Summary:\")\n",
        "model.summary()\n",
        "\n",
        "# ==== Evaluation ====\n",
        "print(\"\\n---------- Evaluation on Training Data -----------\")\n",
        "print(classification_report(y_train, pred_labels_tr))\n",
        "\n",
        "print(\"\\n---------- Evaluation on Test Data -----------\")\n",
        "print(classification_report(y_test, pred_labels_te))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uVhSFD9e7CWP",
        "outputId": "5df99bc8-ca61-42b1-9c79-b12a2927ceb0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available: 1\n",
            "Error setting up GPU: Physical devices cannot be modified after being initialized\n",
            "Shape of X_train:  (60000, 28, 28)\n",
            "Shape of y_train:  (60000,)\n",
            "Shape of X_test:  (10000, 28, 28)\n",
            "Shape of y_test:  (10000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New shape of X_train:  (60000, 784)\n",
            "New shape of X_test:  (10000, 784)\n",
            "Epoch 1/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.8847 - loss: 0.3841 - val_accuracy: 0.9615 - val_loss: 0.1318\n",
            "Epoch 2/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.1153 - val_accuracy: 0.9626 - val_loss: 0.1261\n",
            "Epoch 3/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9746 - loss: 0.0787 - val_accuracy: 0.9688 - val_loss: 0.1059\n",
            "Epoch 4/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9800 - loss: 0.0652 - val_accuracy: 0.9696 - val_loss: 0.1056\n",
            "Epoch 5/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9850 - loss: 0.0465 - val_accuracy: 0.9708 - val_loss: 0.1086\n",
            "Epoch 6/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9867 - loss: 0.0425 - val_accuracy: 0.9697 - val_loss: 0.1191\n",
            "Epoch 7/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.0342 - val_accuracy: 0.9708 - val_loss: 0.1106\n",
            "Epoch 8/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0300 - val_accuracy: 0.9702 - val_loss: 0.1238\n",
            "Epoch 9/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0334 - val_accuracy: 0.9763 - val_loss: 0.1072\n",
            "Epoch 10/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0260 - val_accuracy: 0.9742 - val_loss: 0.1308\n",
            "Epoch 11/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0214 - val_accuracy: 0.9723 - val_loss: 0.1368\n",
            "Epoch 12/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0217 - val_accuracy: 0.9758 - val_loss: 0.1096\n",
            "Epoch 13/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0180 - val_accuracy: 0.9752 - val_loss: 0.1332\n",
            "Epoch 14/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0238 - val_accuracy: 0.9755 - val_loss: 0.1370\n",
            "Epoch 15/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0196 - val_accuracy: 0.9737 - val_loss: 0.1543\n",
            "Epoch 16/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0172 - val_accuracy: 0.9729 - val_loss: 0.1634\n",
            "Epoch 17/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0174 - val_accuracy: 0.9762 - val_loss: 0.1460\n",
            "Epoch 18/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0128 - val_accuracy: 0.9729 - val_loss: 0.1657\n",
            "Epoch 19/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0129 - val_accuracy: 0.9768 - val_loss: 0.1431\n",
            "Epoch 20/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0135 - val_accuracy: 0.9737 - val_loss: 0.1698\n",
            "Epoch 21/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0159 - val_accuracy: 0.9685 - val_loss: 0.1998\n",
            "Epoch 22/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0141 - val_accuracy: 0.9764 - val_loss: 0.1639\n",
            "Epoch 23/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0113 - val_accuracy: 0.9716 - val_loss: 0.2066\n",
            "Epoch 24/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0116 - val_accuracy: 0.9734 - val_loss: 0.2204\n",
            "Epoch 25/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0172 - val_accuracy: 0.9766 - val_loss: 0.1624\n",
            "Epoch 26/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0118 - val_accuracy: 0.9770 - val_loss: 0.1751\n",
            "Epoch 27/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0129 - val_accuracy: 0.9768 - val_loss: 0.1752\n",
            "Epoch 28/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0097 - val_accuracy: 0.9731 - val_loss: 0.1906\n",
            "Epoch 29/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0120 - val_accuracy: 0.9755 - val_loss: 0.2383\n",
            "Epoch 30/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0152 - val_accuracy: 0.9762 - val_loss: 0.2005\n",
            "Epoch 31/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0133 - val_accuracy: 0.9714 - val_loss: 0.2243\n",
            "Epoch 32/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0137 - val_accuracy: 0.9753 - val_loss: 0.2159\n",
            "Epoch 33/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0106 - val_accuracy: 0.9715 - val_loss: 0.2417\n",
            "Epoch 34/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0116 - val_accuracy: 0.9751 - val_loss: 0.2200\n",
            "Epoch 35/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0115 - val_accuracy: 0.9756 - val_loss: 0.2100\n",
            "Epoch 36/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0130 - val_accuracy: 0.9752 - val_loss: 0.2333\n",
            "Epoch 37/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0130 - val_accuracy: 0.9773 - val_loss: 0.1953\n",
            "Epoch 38/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0075 - val_accuracy: 0.9772 - val_loss: 0.1938\n",
            "Epoch 39/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0075 - val_accuracy: 0.9744 - val_loss: 0.2202\n",
            "Epoch 40/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0103 - val_accuracy: 0.9773 - val_loss: 0.2344\n",
            "Epoch 41/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0092 - val_accuracy: 0.9763 - val_loss: 0.2170\n",
            "Epoch 42/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0080 - val_accuracy: 0.9759 - val_loss: 0.2501\n",
            "Epoch 43/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0092 - val_accuracy: 0.9739 - val_loss: 0.2756\n",
            "Epoch 44/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0115 - val_accuracy: 0.9753 - val_loss: 0.2488\n",
            "Epoch 45/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0098 - val_accuracy: 0.9770 - val_loss: 0.2550\n",
            "Epoch 46/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0077 - val_accuracy: 0.9764 - val_loss: 0.2629\n",
            "Epoch 47/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0069 - val_accuracy: 0.9770 - val_loss: 0.2519\n",
            "Epoch 48/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0074 - val_accuracy: 0.9755 - val_loss: 0.2953\n",
            "Epoch 49/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0093 - val_accuracy: 0.9763 - val_loss: 0.2596\n",
            "Epoch 50/50\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0073 - val_accuracy: 0.9772 - val_loss: 0.2861\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"DFF-Model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"DFF-Model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ Hidden-Layer-1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Hidden-Layer-2 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Hidden-Layer-3 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Output-Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ Hidden-Layer-1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Hidden-Layer-2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Hidden-Layer-3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Output-Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m333,440\u001b[0m (1.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">333,440</span> (1.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,146\u001b[0m (434.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,146</span> (434.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m222,294\u001b[0m (868.34 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">222,294</span> (868.34 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------- Evaluation on Training Data -----------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      5923\n",
            "           1       1.00      1.00      1.00      6742\n",
            "           2       0.99      1.00      0.99      5958\n",
            "           3       1.00      0.99      0.99      6131\n",
            "           4       0.99      1.00      0.99      5842\n",
            "           5       0.99      0.99      0.99      5421\n",
            "           6       1.00      1.00      1.00      5918\n",
            "           7       0.99      1.00      0.99      6265\n",
            "           8       0.99      0.99      0.99      5851\n",
            "           9       0.99      0.99      0.99      5949\n",
            "\n",
            "    accuracy                           0.99     60000\n",
            "   macro avg       0.99      0.99      0.99     60000\n",
            "weighted avg       0.99      0.99      0.99     60000\n",
            "\n",
            "\n",
            "---------- Evaluation on Test Data -----------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.97      0.98      0.97      1032\n",
            "           3       0.97      0.97      0.97      1010\n",
            "           4       0.98      0.98      0.98       982\n",
            "           5       0.98      0.97      0.98       892\n",
            "           6       0.98      0.98      0.98       958\n",
            "           7       0.96      0.98      0.97      1028\n",
            "           8       0.97      0.96      0.97       974\n",
            "           9       0.97      0.96      0.97      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Input\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# GPU setup\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"✅ GPU is available and memory growth set.\")\n",
        "    except RuntimeError as e:\n",
        "        print(\"❌ GPU setup error:\", e)\n",
        "else:\n",
        "    print(\"❌ No GPU found. Using CPU.\")\n",
        "\n",
        "# Load and preprocess CIFAR-10\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "X_train = X_train.reshape(-1, 32 * 32 * 3).astype(\"float32\") / 255.0\n",
        "X_test = X_test.reshape(-1, 32 * 32 * 3).astype(\"float32\") / 255.0\n",
        "y_train = y_train.flatten()\n",
        "y_test = y_test.flatten()\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "# Build the ANN model\n",
        "def build_ann_model():\n",
        "    model = Sequential(name=\"CIFAR10-ANN\")\n",
        "    model.add(Input(shape=(32 * 32 * 3,)))\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Callbacks\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "model = build_ann_model()\n",
        "history = model.fit(X_train, y_train_cat,\n",
        "                    epochs=100,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stop, reduce_lr],\n",
        "                    verbose=2)\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
        "print(f\"\\n✅ Final Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "# Predictions and classification report\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "print(\"\\nClassification Report on Test Set:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nm1HqmXH_ZTe",
        "outputId": "89dbae42-8d23-4b9c-e8f3-cf27b0aeff08"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ GPU setup error: Physical devices cannot be modified after being initialized\n",
            "Epoch 1/100\n",
            "704/704 - 11s - 16ms/step - accuracy: 0.3140 - loss: 2.0620 - val_accuracy: 0.3568 - val_loss: 1.9103 - learning_rate: 1.0000e-03\n",
            "Epoch 2/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.3861 - loss: 1.8524 - val_accuracy: 0.3920 - val_loss: 1.8385 - learning_rate: 1.0000e-03\n",
            "Epoch 3/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.4059 - loss: 1.7982 - val_accuracy: 0.3914 - val_loss: 1.8378 - learning_rate: 1.0000e-03\n",
            "Epoch 4/100\n",
            "704/704 - 6s - 8ms/step - accuracy: 0.4182 - loss: 1.7765 - val_accuracy: 0.4088 - val_loss: 1.8028 - learning_rate: 1.0000e-03\n",
            "Epoch 5/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.4133 - loss: 1.7821 - val_accuracy: 0.4232 - val_loss: 1.7574 - learning_rate: 1.0000e-03\n",
            "Epoch 6/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.4200 - loss: 1.7610 - val_accuracy: 0.4252 - val_loss: 1.7855 - learning_rate: 1.0000e-03\n",
            "Epoch 7/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.4309 - loss: 1.7444 - val_accuracy: 0.4552 - val_loss: 1.6976 - learning_rate: 1.0000e-03\n",
            "Epoch 8/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.4334 - loss: 1.7416 - val_accuracy: 0.4686 - val_loss: 1.6688 - learning_rate: 1.0000e-03\n",
            "Epoch 9/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.4378 - loss: 1.7300 - val_accuracy: 0.4670 - val_loss: 1.6522 - learning_rate: 1.0000e-03\n",
            "Epoch 10/100\n",
            "704/704 - 6s - 8ms/step - accuracy: 0.4409 - loss: 1.7199 - val_accuracy: 0.4564 - val_loss: 1.6807 - learning_rate: 1.0000e-03\n",
            "Epoch 11/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.4464 - loss: 1.7157 - val_accuracy: 0.4256 - val_loss: 1.7686 - learning_rate: 1.0000e-03\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.4474 - loss: 1.7120 - val_accuracy: 0.4772 - val_loss: 1.6653 - learning_rate: 1.0000e-03\n",
            "Epoch 13/100\n",
            "704/704 - 5s - 8ms/step - accuracy: 0.4606 - loss: 1.6791 - val_accuracy: 0.5038 - val_loss: 1.6038 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.4667 - loss: 1.6731 - val_accuracy: 0.4992 - val_loss: 1.6058 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.4674 - loss: 1.6646 - val_accuracy: 0.5010 - val_loss: 1.6028 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.4694 - loss: 1.6682 - val_accuracy: 0.4988 - val_loss: 1.6110 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.4723 - loss: 1.6589 - val_accuracy: 0.5108 - val_loss: 1.6016 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.4735 - loss: 1.6549 - val_accuracy: 0.4974 - val_loss: 1.6054 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "704/704 - 5s - 8ms/step - accuracy: 0.4766 - loss: 1.6475 - val_accuracy: 0.5116 - val_loss: 1.5824 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.4773 - loss: 1.6470 - val_accuracy: 0.4856 - val_loss: 1.6222 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.4812 - loss: 1.6444 - val_accuracy: 0.4948 - val_loss: 1.5992 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.4804 - loss: 1.6418 - val_accuracy: 0.5044 - val_loss: 1.5788 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.4842 - loss: 1.6343 - val_accuracy: 0.5010 - val_loss: 1.5842 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.4854 - loss: 1.6280 - val_accuracy: 0.5102 - val_loss: 1.5783 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.4829 - loss: 1.6332 - val_accuracy: 0.5048 - val_loss: 1.5709 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.4909 - loss: 1.6228 - val_accuracy: 0.4960 - val_loss: 1.5986 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.4891 - loss: 1.6215 - val_accuracy: 0.5066 - val_loss: 1.5873 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "704/704 - 5s - 8ms/step - accuracy: 0.4907 - loss: 1.6187 - val_accuracy: 0.5104 - val_loss: 1.5733 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.4980 - loss: 1.6050 - val_accuracy: 0.5244 - val_loss: 1.5380 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5010 - loss: 1.5937 - val_accuracy: 0.5280 - val_loss: 1.5396 - learning_rate: 2.5000e-04\n",
            "Epoch 31/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5038 - loss: 1.5933 - val_accuracy: 0.5322 - val_loss: 1.5288 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.5036 - loss: 1.5918 - val_accuracy: 0.5260 - val_loss: 1.5363 - learning_rate: 2.5000e-04\n",
            "Epoch 33/100\n",
            "704/704 - 5s - 8ms/step - accuracy: 0.5053 - loss: 1.5869 - val_accuracy: 0.5330 - val_loss: 1.5297 - learning_rate: 2.5000e-04\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5049 - loss: 1.5855 - val_accuracy: 0.5316 - val_loss: 1.5316 - learning_rate: 2.5000e-04\n",
            "Epoch 35/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5138 - loss: 1.5765 - val_accuracy: 0.5338 - val_loss: 1.5241 - learning_rate: 1.2500e-04\n",
            "Epoch 36/100\n",
            "704/704 - 3s - 5ms/step - accuracy: 0.5122 - loss: 1.5764 - val_accuracy: 0.5328 - val_loss: 1.5206 - learning_rate: 1.2500e-04\n",
            "Epoch 37/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5132 - loss: 1.5757 - val_accuracy: 0.5388 - val_loss: 1.5144 - learning_rate: 1.2500e-04\n",
            "Epoch 38/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.5155 - loss: 1.5702 - val_accuracy: 0.5364 - val_loss: 1.5206 - learning_rate: 1.2500e-04\n",
            "Epoch 39/100\n",
            "704/704 - 5s - 8ms/step - accuracy: 0.5121 - loss: 1.5741 - val_accuracy: 0.5340 - val_loss: 1.5241 - learning_rate: 1.2500e-04\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.5136 - loss: 1.5727 - val_accuracy: 0.5336 - val_loss: 1.5193 - learning_rate: 1.2500e-04\n",
            "Epoch 41/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5167 - loss: 1.5688 - val_accuracy: 0.5394 - val_loss: 1.5168 - learning_rate: 6.2500e-05\n",
            "Epoch 42/100\n",
            "704/704 - 3s - 5ms/step - accuracy: 0.5205 - loss: 1.5613 - val_accuracy: 0.5348 - val_loss: 1.5200 - learning_rate: 6.2500e-05\n",
            "Epoch 43/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5175 - loss: 1.5645 - val_accuracy: 0.5392 - val_loss: 1.5130 - learning_rate: 6.2500e-05\n",
            "Epoch 44/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5188 - loss: 1.5616 - val_accuracy: 0.5382 - val_loss: 1.5205 - learning_rate: 6.2500e-05\n",
            "Epoch 45/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5182 - loss: 1.5634 - val_accuracy: 0.5420 - val_loss: 1.5128 - learning_rate: 6.2500e-05\n",
            "Epoch 46/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5173 - loss: 1.5611 - val_accuracy: 0.5378 - val_loss: 1.5165 - learning_rate: 6.2500e-05\n",
            "Epoch 47/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5178 - loss: 1.5605 - val_accuracy: 0.5388 - val_loss: 1.5172 - learning_rate: 6.2500e-05\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.5200 - loss: 1.5605 - val_accuracy: 0.5356 - val_loss: 1.5156 - learning_rate: 6.2500e-05\n",
            "Epoch 49/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.5185 - loss: 1.5592 - val_accuracy: 0.5396 - val_loss: 1.5103 - learning_rate: 3.1250e-05\n",
            "Epoch 50/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.5181 - loss: 1.5606 - val_accuracy: 0.5414 - val_loss: 1.5115 - learning_rate: 3.1250e-05\n",
            "Epoch 51/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5200 - loss: 1.5571 - val_accuracy: 0.5358 - val_loss: 1.5162 - learning_rate: 3.1250e-05\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.5220 - loss: 1.5561 - val_accuracy: 0.5392 - val_loss: 1.5122 - learning_rate: 3.1250e-05\n",
            "Epoch 53/100\n",
            "704/704 - 6s - 8ms/step - accuracy: 0.5192 - loss: 1.5553 - val_accuracy: 0.5406 - val_loss: 1.5121 - learning_rate: 1.5625e-05\n",
            "Epoch 54/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.5191 - loss: 1.5567 - val_accuracy: 0.5386 - val_loss: 1.5110 - learning_rate: 1.5625e-05\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5228 - loss: 1.5551 - val_accuracy: 0.5404 - val_loss: 1.5121 - learning_rate: 1.5625e-05\n",
            "Epoch 56/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.5223 - loss: 1.5545 - val_accuracy: 0.5400 - val_loss: 1.5106 - learning_rate: 7.8125e-06\n",
            "Epoch 57/100\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5182 - loss: 1.5589 - val_accuracy: 0.5412 - val_loss: 1.5106 - learning_rate: 7.8125e-06\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.5213 - loss: 1.5556 - val_accuracy: 0.5378 - val_loss: 1.5103 - learning_rate: 7.8125e-06\n",
            "Epoch 59/100\n",
            "704/704 - 5s - 8ms/step - accuracy: 0.5179 - loss: 1.5536 - val_accuracy: 0.5388 - val_loss: 1.5117 - learning_rate: 3.9063e-06\n",
            "Epoch 60/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.5214 - loss: 1.5514 - val_accuracy: 0.5384 - val_loss: 1.5131 - learning_rate: 3.9063e-06\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5214 - loss: 1.5524 - val_accuracy: 0.5396 - val_loss: 1.5123 - learning_rate: 3.9063e-06\n",
            "Epoch 62/100\n",
            "704/704 - 5s - 8ms/step - accuracy: 0.5207 - loss: 1.5560 - val_accuracy: 0.5406 - val_loss: 1.5134 - learning_rate: 1.9531e-06\n",
            "Epoch 63/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.5215 - loss: 1.5565 - val_accuracy: 0.5398 - val_loss: 1.5106 - learning_rate: 1.9531e-06\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5198 - loss: 1.5584 - val_accuracy: 0.5398 - val_loss: 1.5113 - learning_rate: 1.9531e-06\n",
            "Epoch 65/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.5211 - loss: 1.5600 - val_accuracy: 0.5406 - val_loss: 1.5112 - learning_rate: 9.7656e-07\n",
            "Epoch 66/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.5235 - loss: 1.5517 - val_accuracy: 0.5398 - val_loss: 1.5114 - learning_rate: 9.7656e-07\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 67: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
            "704/704 - 5s - 7ms/step - accuracy: 0.5213 - loss: 1.5556 - val_accuracy: 0.5404 - val_loss: 1.5123 - learning_rate: 9.7656e-07\n",
            "Epoch 68/100\n",
            "704/704 - 3s - 4ms/step - accuracy: 0.5240 - loss: 1.5531 - val_accuracy: 0.5404 - val_loss: 1.5103 - learning_rate: 4.8828e-07\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-897347fdcf75>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n✅ Final Test Accuracy: {acc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_evaluating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}